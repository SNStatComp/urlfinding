{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urlfinding as uf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from the web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start scraping the following information is needed:\n",
    "- **base_file**: A .csv file with a list of enterprises for which you want to find the webaddress. If you want to use the pretrained ML model provided (_data/model.pkl_) the file must at least include the following columns:  _id, tradename, legalname, address, postalcode and locality_. The column names can be specified in a mapping file (see _config/mappings.yml_ for an example)\n",
    "- **googleconfig**: This file contains your credentials for using the [Google custom search engine API](https://developers.google.com/custom-search/v1/overview)\n",
    "- **blacklist**: A file containing urls you want to exclude from your search\n",
    "- **nrows**: Number of enterprises you want to search for. Google provides 100 queries per day for free. In this example for every enterprise 6 queries are performed, thus for 10 enterprises 6 * 10 = 60 queries. Every query returns at most 10 search results.\n",
    "\n",
    "This function creates a file (<_YYYYMMDD_>_searchResult.csv_) in the _data_ folder containing the search results, where YYYYMMDD is the formatted current date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_file    = './data/NSIs.csv'\n",
    "googleconfig = './config/config.yml'\n",
    "blacklist    = './data/blacklist.txt'\n",
    "nrows        = 10\n",
    "\n",
    "uf.scrape.start(base_file, googleconfig, blacklist, nrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the feature file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next create the features used for training your Machine Learning model or predicting using your model.\n",
    "- **date**: Used for adding a 'timestamp' to the name of the created feature file\n",
    "- **data_files**: list of files containing the search results\n",
    "- **blacklist**: see above\n",
    "\n",
    "This function creates the feature file <_YYYYMMDD_>_features_\\__agg.csv_ in the _data_ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date       = '20200110'\n",
    "data_files = ['./data/20200109searchResult.csv'] # change this, should contain the file(s) you created\n",
    "blacklist  = './data/blacklist.txt'\n",
    "\n",
    "uf.process.start(date, data_files, blacklist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally predict urls using the provided or your own trained ML model\n",
    "- **model_file**: Pickle file containing the ML model (created with our package)\n",
    "- **feature_file**: file containing the features\n",
    "- **base_file**: The same file that was used for scraping (see above)\n",
    "\n",
    "This function creates the file <_base_\\_file>_\\_url.csv_ in the _data_ folder containing the predicted urls. This file contains all data from the base file with 3 columns added:\n",
    "- **host**: the predicted url\n",
    "- **eqPred**: An indicator showing whether the predicted url is the right one\n",
    "- **pTrue**: An indicator showing the confidence of the prediction, a number between 0 and 1 where 0: almost certain not the url and 1: almost certain the right url. **eqPred** is derived from **pTrue**: if pTrue>0.5 then eqPred=True else eqPred=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file   = './data/model.pkl'\n",
    "feature_file = './data/20200110features_agg.csv'\n",
    "base_file    = './data/NSIs.csv'\n",
    "\n",
    "uf.predict.start(feature_file, model_file, base_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
